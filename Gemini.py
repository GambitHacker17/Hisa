# meta developer: @MartyyyK
# requires: aiohttp pytz markdown_it_py

import re
import os
import io
import random
import socket
import asyncio
import logging
import aiohttp
import tempfile
import base64
from datetime import datetime
from markdown_it import MarkdownIt
import pytz
from telethon import types
from telethon.tl.types import Message, DocumentAttributeFilename
from telethon.utils import get_display_name, get_peer_id
from telethon.errors.rpcerrorlist import MessageTooLongError, ChatAdminRequiredError
from telethon.errors.rpcerrorlist import UserNotParticipantError, ChannelPrivateError
from .. import loader, utils
from ..inline.types import InlineCall

logger = logging.getLogger(__name__)

DB_HISTORY_KEY = "gemini_conversations_v4"
DB_geminiauto_HISTORY_KEY = "gemini_geminiauto_conversations_v1"
DB_IMPERSONATION_KEY = "gemini_impersonation_chats"
GEMINI_TIMEOUT = 840
MAX_FFMPEG_SIZE = 90 * 1024 * 1024
GEMINI_API_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent"

class GoogleAPIError(Exception):
    def __init__(self, message, status_code=None, details=None):
        super().__init__(message)
        self.status_code = status_code
        self.details = details

@loader.tds
class Gemini(loader.Module):
    """Google Gemini AI"""
    strings = {
        "name": "Gemini",
        "cfg_api_key_doc": "API –∫–ª—é—á–∏ Google Gemini, –ø–∏—à–∏—Ç–µ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é <key1>, <key2>. –ü–æ—Å–ª–µ –≤–≤–æ–¥–∞ –∫–ª—é—á–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —é–∑–µ—Ä–±–æ—Ç",
        "cfg_model_name_doc": "–ú–æ–¥–µ–ª—å Gemini",
        "cfg_buttons_doc": "–í–∫–ª—é—á–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∫–Ω–æ–ø–∫–∏",
        "cfg_system_instruction_doc": "–°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (–ø—Ä–æ–º–ø—Ç) –¥–ª—è Gemini",
        "cfg_max_history_length_doc": "–ú–∞–∫—Å. –∫–æ–ª-–≤–æ –ø–∞—Ä '–≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç' –≤ –ø–∞–º—è—Ç–∏ (0 - –±–µ–∑ –ª–∏–º–∏—Ç–∞).",
        "cfg_timezone_doc": "–ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å. –°–ø–∏—Å–æ–∫: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones",
        "cfg_proxy_doc": "–ü—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ: http://user:pass@host:port",
        "cfg_impersonation_prompt_doc": "–ü—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞. {my_name} –∏ {chat_history} –±—É–¥—É—Ç –∑–∞–º–µ–Ω–µ–Ω—ã",
        "cfg_impersonation_history_limit_doc": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —á–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞",
        "cfg_impersonation_reply_chance_doc": "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ geminiauto <0.0 - 1.0>",
        "no_api_key": '‚ùóÔ∏è <b>Api –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω</b>\n–ü–æ–ª—É—á–∏—Ç—å Api –∫–ª—é—á –º–æ–∂–Ω–æ <a href="https://aistudio.google.com/app/apikey">–∑–¥–µ—Å—å</a>\n<b>–î–æ–±–∞–≤—å—Ç–µ –∫–ª—é—á –≤ –∫–æ–Ω—Ñ–∏–≥–µ –º–æ–¥—É–ª—è</b>',
        "all_keys_exhausted": "‚ùóÔ∏è <b>–í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ API –∫–ª—é—á–∏ ({}) –∏—Å—á–µ—Ä–ø–∞–ª–∏ —Å–≤–æ—é –∫–≤–æ—Ç—É</b>\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –Ω–æ–≤—ã–µ –∫–ª—é—á–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ",
        "no_prompt_or_media": "‚ö†Ô∏è <i>–ù—É–∂–µ–Ω —Ç–µ–∫—Å—Ç –∏–ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –º–µ–¥–∏–∞/—Ñ–∞–π–ª.</i>",
        "processing": "<emoji document_id=5350356823528455446>‚ú®</emoji> <b>–û–±—Ä–∞–±–æ—Ç–∫–∞...</b>",
        "api_error": "‚ùóÔ∏è <b>–û—à–∏–±–∫–∞ API:</b>\n<code>{}</code>",
        "api_timeout": f"‚ùóÔ∏è <b>–¢–∞–π–º–∞—É—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini API ({GEMINI_TIMEOUT} —Å–µ–∫)</b>",
        "blocked_error": "üö´ <b>–ó–∞–ø—Ä–æ—Å/–æ—Ç–≤–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω</b>\n<code>{}</code>",
        "generic_error": "‚ùóÔ∏è <b>–û—à–∏–±–∫–∞:</b>\n<code>{}</code>",
        "question_prefix": "üí¨ <b>–ó–∞–ø—Ä–æ—Å:</b>",
        "response_prefix": "<emoji document_id=5325547803936572038>‚ú®</emoji> <b>Gemini:</b>",
        "unsupported_media_type": "‚ö†Ô∏è <b>–§–æ—Ä–º–∞—Ç –º–µ–¥–∏–∞ ({}) –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è</b>",
        "memory_status": "üß† [{}/{}]",
        "memory_status_unlimited": "üß† [{}/‚àû]",
        "memory_cleared": "üßπ <b>–ü–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞</b>",
        "memory_cleared_geminiauto": "üßπ <b>–ü–∞–º—è—Ç—å geminiauto –≤ —ç—Ç–æ–º —á–∞—Ç–µ –æ—á–∏—â–µ–Ω–∞</b>",
        "no_memory_to_clear": "‚ÑπÔ∏è <b>–í —ç—Ç–æ–º —á–∞—Ç–µ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏</b>",
        "no_geminiauto_memory_to_clear": "‚ÑπÔ∏è <b>–í —ç—Ç–æ–º —á–∞—Ç–µ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ geminiauto</b>",
        "memory_chats_title": "üß† <b>–ß–∞—Ç—ã —Å –∏—Å—Ç–æ—Ä–∏–µ–π ({}):</b>",
        "memory_chat_line": "  ‚Ä¢ {} (<code>{}</code>)",
        "no_memory_found": "‚ÑπÔ∏è –ü–∞–º—è—Ç—å Gemini –ø—É—Å—Ç–∞",
        "media_reply_placeholder": "[–æ—Ç–≤–µ—Ç –Ω–∞ –º–µ–¥–∏–∞]",
        "btn_clear": "üßπ –û—á–∏—Å—Ç–∏—Ç—å",
        "btn_regenerate": "üîÑ –î—Ä—É–≥–æ–π –æ—Ç–≤–µ—Ç",
        "no_last_request": "–ü–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏",
        "memory_fully_cleared": "üßπ <b>–í—Å—è –ø–∞–º—è—Ç—å Gemini –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–∞ (–∑–∞—Ç—Ä–æ–Ω—É—Ç–æ {} —á–∞—Ç–æ–≤)</b>",
        "geminiauto_memory_fully_cleared": "üßπ <b>–í—Å—è –ø–∞–º—è—Ç—å geminiauto –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–∞ (–∑–∞—Ç—Ä–æ–Ω—É—Ç–æ {} —á–∞—Ç–æ–≤)</b>",
        "no_memory_to_fully_clear": "‚ÑπÔ∏è <b>–ü–∞–º—è—Ç—å Gemini –ø—É—Å—Ç–∞</b>",
        "no_geminiauto_memory_to_fully_clear": "‚ÑπÔ∏è <b>–ü–∞–º—è—Ç—å geminiauto –ø—É—Å—Ç–∞</b>",
        "response_too_long": "–û—Ç–≤–µ—Ç Gemini –±—ã–ª —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ –≤–∏–¥–µ —Ñ–∞–π–ª–∞",
        "gclear_usage": "‚ÑπÔ∏è <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:</b> <code>.gclear [auto]</code>",
        "gres_usage": "‚ÑπÔ∏è <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:</b> <code>.gres [auto]</code>",
        "auto_mode_on": "üé≠ <b>–†–µ–∂–∏–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞ –≤–∫–ª—é—á–µ–Ω –≤ —ç—Ç–æ–º —á–∞—Ç–µ</b>\n–Ø –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é {}%",
        "auto_mode_off": "üé≠ <b>–†–µ–∂–∏–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞ –≤—ã–∫–ª—é—á–µ–Ω –≤ —ç—Ç–æ–º —á–∞—Ç–µ</b>",
        "auto_mode_chats_title": "üé≠ <b>–ß–∞—Ç—ã —Å –∞–∫—Ç–∏–≤–Ω—ã–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–æ–º ({}):</b>",
        "no_auto_mode_chats": "‚ÑπÔ∏è –ù–µ—Ç —á–∞—Ç–æ–≤ —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º —Ä–µ–∂–∏–º–æ–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞",
        "auto_mode_usage": "‚ÑπÔ∏è <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:</b> <code>.geminiauto on/off</code>",
        "gch_usage": "‚ÑπÔ∏è <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:</b>\n<code>.gch <–∫–æ–ª-–≤–æ> <–≤–æ–ø—Ä–æ—Å></code>\n<code>.gch <id —á–∞—Ç–∞> <–∫–æ–ª-–≤–æ> <–≤–æ–ø—Ä–æ—Å></code>",
        "gch_processing": "<emoji document_id=5386367538735104399>‚åõÔ∏è</emoji> <b>–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é {} —Å–æ–æ–±—â–µ–Ω–∏–π...</b>",
        "gch_result_caption": "–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö {} —Å–æ–æ–±—â–µ–Ω–∏–π",
        "gch_result_caption_from_chat": "–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö {} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —á–∞—Ç–∞ <b>{}</b>",
        "gch_invalid_args": "‚ùóÔ∏è <b>–ù–µ–≤–µ—Ä–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã</b>\n{}",
        "gch_chat_error": "‚ùóÔ∏è <b>–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —á–∞—Ç—É</b> <code>{}</code>: <i>{}</i>",
        "region_blocked_error": "‚ùóÔ∏è <b>–í –¥–∞–Ω–Ω–æ–º —Ä–µ–≥–∏–æ–Ω–µ Gemini API –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω</b>\n–°–∫–∞—á–∞–π—Ç–µ VPN (–¥–ª—è –ø–∫/—Ç–µ–ª) –∏–ª–∏ –ø–æ—Å—Ç–∞–≤—å—Ç–µ –ø—Ä–æ–∫—Å–∏ (–ø–ª–∞—Ç–Ω—ã–π/–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π)\n–ò–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–æ–∫—Å–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ –º–æ–¥—É–ª—è –∫–æ–º–∞–Ω–¥–æ–π <code>.cfg Gemini</code>\n\n<b>–¢–µ–∫—É—â–∏–π –ø—Ä–æ–∫—Å–∏:</b> <code>{}</code>",
        "quota_exceeded_error": "‚ùóÔ∏è <b>–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç Google Gemini API –¥–ª—è –º–æ–¥–µ–ª–∏ <code>{}</code></b>\n\n–ß–∞—â–µ –≤—Å–µ–≥–æ —ç—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–º —Ç–∞—Ä–∏—Ñ–µ\n–í—ã –º–æ–∂–µ—Ç–µ:\n‚Ä¢ –ü–æ–¥–æ–∂–¥–∞—Ç—å, –ø–æ–∫–∞ –ª–∏–º–∏—Ç —Å–±—Ä–æ—Å–∏—Ç—Å—è (–æ–±—ã—á–Ω–æ —Ä–∞–∑ –≤ —Å—É—Ç–∫–∏)\n‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–≤–æ–π —Ç–∞—Ä–∏—Ñ–Ω—ã–π –ø–ª–∞–Ω –≤ <a href='https://aistudio.google.com/app/billing'>Google AI Studio</a>\n‚Ä¢ –£–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –æ –ª–∏–º–∏—Ç–∞—Ö <a href='https://ai.google.dev/gemini-api/docs/rate-limits'>–∑–¥–µ—Å—å</a>\n\n<b>–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:</b>\n<code>{}</code>",
        "server_error_500": "‚ùóÔ∏è <b>–û—à–∏–±–∫–∞ 500 –æ—Ç Google API</b>\n–≠—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç –º–µ–¥–∏–∞ (—Ñ–∞–π–ª –∏–ª–∏ –µ—â–µ —á—Ç–æ-—Ç–æ), –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –æ—Ç–ø—Ä–∞–≤–∏–ª, –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n–¢–∞–∫–æ–µ —Å–ª—É—á–∞–µ—Ç—Å—è –ø–æ —Ç–∞–∫–æ–π –ø—Ä–∏—á–∏–Ω–µ:\n‚Ä¢ –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –≤ –ø—Ä–∏–Ω—Ü–∏–ø–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è Gemini/Google\n‚Ä¢ –í—Ä–µ–º–µ–Ω–Ω—ã–π —Å–±–æ–π –Ω–∞ —Å–µ—Ä–≤–µ—Ä–∞—Ö Google. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–∑–∂–µ",
        "network_error": "‚ùóÔ∏è <b>–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞:</b>\n<code>{}</code>\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏",
        "invalid_api_key": "‚ùóÔ∏è <b>–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á</b>\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∫–ª—é—á–∞ –≤ –∫–æ–Ω—Ñ–∏–≥–µ –º–æ–¥—É–ª—è\n–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤—ã–π –∫–ª—é—á –º–æ–∂–Ω–æ <a href='https://aistudio.google.com/app/apikey'>–∑–¥–µ—Å—å</a>",
        "file_too_large": "‚ùóÔ∏è <b>–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π</b>\n–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {} –ú–ë",
        "ffmpeg_error": "‚ùóÔ∏è <b>–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞</b>\n–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞",
        "access_denied": "‚ùóÔ∏è <b>–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω</b>\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —á–∞—Ç—É –∏–ª–∏ —Ñ–∞–π–ª—É",
        "unknown_error": "‚ùóÔ∏è <b>–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞</b>\n<code>{}</code>\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–∑–∂–µ",
        "system_instruction_too_long": "‚ùóÔ∏è <b>–°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è</b>\n–¢–µ–∫—É—â–∞—è –¥–ª–∏–Ω–∞: {} —Å–∏–º–≤–æ–ª–æ–≤\n–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: 8192 —Å–∏–º–≤–æ–ª–∞\n–£–º–µ–Ω—å—à–∏—Ç–µ –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç",
    }
    TEXT_MIME_TYPES = {
        "text/plain", "text/markdown", "text/html", "text/css", "text/csv",
        "application/json", "application/xml", "application/x-python", "text/x-python",
        "application/javascript", "application/x-sh",
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "api_key", "", self.strings["cfg_api_key_doc"],
                validator=loader.validators.Hidden()
            ),
            loader.ConfigValue("model_name", "gemini-2.5-flash", self.strings["cfg_model_name_doc"]),
            loader.ConfigValue("interactive_buttons", True, self.strings["cfg_buttons_doc"], validator=loader.validators.Boolean()),
            loader.ConfigValue("system_instruction", "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π HTML —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–µ.", self.strings["cfg_system_instruction_doc"], validator=loader.validators.String()),
            loader.ConfigValue("max_history_length", 800, self.strings["cfg_max_history_length_doc"], validator=loader.validators.Integer(minimum=0)),
            loader.ConfigValue("timezone", "Europe/Moscow", self.strings["cfg_timezone_doc"]),
            loader.ConfigValue("proxy", "", self.strings["cfg_proxy_doc"]),
            loader.ConfigValue(
                "impersonation_prompt",
                (
                    "–¢—ã ‚Äî —ç—Ç–æ —è, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å Telegram –ø–æ –∏–º–µ–Ω–∏ {my_name}. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ—Ç–≤–µ—á–∞—Ç—å –≤ —á–∞—Ç–µ –æ—Ç –º–æ–µ–≥–æ –∏–º–µ–Ω–∏, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö."
                    "–í–µ–¥–∏ —Å–µ–±—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —á–µ–ª–æ–≤–µ–∫, –∞ –Ω–µ –∫–∞–∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ù–µ –ø—Ä–∏–∑–Ω–∞–≤–∞–π—Å—è, —á—Ç–æ —Ç—ã ‚Äî –ò–ò, –¥–∞–∂–µ –µ—Å–ª–∏ —Ç–µ–±—è —Å–ø—Ä–æ—Å—è—Ç –Ω–∞–ø—Ä—è–º—É—é."
                    "–¢–≤–æ—è –ª–∏—á–Ω–æ—Å—Ç—å: [–ó–¥–µ—Å—å –æ–ø–∏—à–∏—Ç–µ —Å–≤–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä: –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π, —Å–µ—Ä—å–µ–∑–Ω—ã–π, —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —Ç.–¥.].\n"
                    "–ü—Ä–∞–≤–∏–ª–∞:\n- –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.\n- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π HTML —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–µ.\n- –ò—Å–ø–æ–ª—å–∑—É–π –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —è–∑—ã–∫, —Å–ª–µ–Ω–≥.\n- –ù–µ —Å—Ç–∞–≤—å —Ç–æ—á–∫—É –≤ –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n- –ù–∞ –º–µ–¥–∏–∞ (—Å—Ç–∏–∫–µ—Ä, —Ñ–æ—Ç–æ) —Ä–µ–∞–≥–∏—Ä—É–π –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ ('–ª–æ–ª', '–æ—Ä—É', '–∂–∏–∑–∞' –∏ —Ç.–¥.).\n- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ—Ñ–∏–∫—Å—ã –∏ –∫–∞–≤—ã—á–∫–∏.\n\n"
                    "–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞:\n{chat_history}\n\n{my_name}:"
                ),
                self.strings["cfg_impersonation_prompt_doc"],
                validator=loader.validators.String(),
            ),
            loader.ConfigValue("impersonation_history_limit", 80, self.strings["cfg_impersonation_history_limit_doc"], validator=loader.validators.Integer(minimum=5, maximum=100)),
            loader.ConfigValue("impersonation_reply_chance", 0.25, self.strings["cfg_impersonation_reply_chance_doc"], validator=loader.validators.Float(minimum=0.0, maximum=1.0)),
        )
        self.conversations = {}
        self.geminiauto_conversations = {}
        self.last_requests = {}
        self.impersonation_chats = set()
        self._lock = asyncio.Lock()
        self.memory_disabled_chats = set()

    async def client_ready(self, client, db):
        self.client = client
        self.db = db
        self.me = await client.get_me()

        await self._migrate_keys()

        self.api_keys = [k.strip() for k in self.config["api_key"].split(",") if k.strip()]
        self.current_api_key_index = 0
        self.conversations = self._load_history_from_db(DB_HISTORY_KEY)
        self.geminiauto_conversations = self._load_history_from_db(DB_geminiauto_HISTORY_KEY)
        self.impersonation_chats = set(self.db.get(self.strings["name"], DB_IMPERSONATION_KEY, []))
        self.safety_settings = [{"category": c, "threshold": "BLOCK_NONE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]]
        self._configure_proxy()
        if not self.api_keys:
            logger.warning("Gemini: API –∫–ª—é—á(–∏) –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω(—ã)!")

    async def _migrate_keys(self):
        module_config = self.db.get(self.strings["name"], "config", {})
        old_keys_list = module_config.get("api_keys")

        if isinstance(old_keys_list, list) and old_keys_list:
            new_string = ",".join(old_keys_list)

            module_config["api_key"] = new_string
            del module_config["api_keys"]

            self.db.set(self.strings["name"], "config", module_config)
            self.config["api_key"] = new_string

            logger.info("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è API –∫–ª—é—á–µ–π Gemini —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –≤ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç")

    async def _prepare_parts(self, message: Message, custom_text: str = None):
        final_parts, warnings = [], []
        prompt_text_chunks = []
        user_args = custom_text if custom_text is not None else utils.get_args_raw(message)
        reply = await message.get_reply_message()

        if reply and getattr(reply, "text", None):
            try:
                reply_sender = await reply.get_sender()
                reply_author_name = get_display_name(reply_sender) if reply_sender else "Unknown"
                if not reply_author_name:
                    reply_author_name = "Unknown"
                prompt_text_chunks.append(f"{reply_author_name}: {reply.text}")
            except Exception:
                prompt_text_chunks.append(f"–û—Ç–≤–µ—Ç –Ω–∞: {reply.text}")

        try:
            current_sender = await message.get_sender()
            current_user_name = get_display_name(current_sender) if current_sender else "User"
            if not current_user_name:
                current_user_name = "User"
            prompt_text_chunks.append(f"{current_user_name}: {user_args or ''}")
        except Exception:
            prompt_text_chunks.append(f"–ó–∞–ø—Ä–æ—Å: {user_args or ''}")

        media_source = message if message.media or message.sticker else reply
        has_media = bool(media_source and (media_source.media or media_source.sticker))

        if has_media:
            if media_source.sticker and hasattr(media_source.sticker, 'mime_type') and media_source.sticker.mime_type == 'application/x-tgsticker':
                alt_text = next((attr.alt for attr in media_source.sticker.attributes if isinstance(attr, types.DocumentAttributeSticker)), "?")
                prompt_text_chunks.append(f"[–û—Ç–ø—Ä–∞–≤–ª–µ–Ω –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∏–∫–µ—Ä: {alt_text}]")
            else:
                media, mime_type, filename = media_source.media, "application/octet-stream", "file"
                if media_source.photo:
                    mime_type = "image/jpeg"
                elif hasattr(media_source, "document") and media_source.document:
                    mime_type = getattr(media_source.document, "mime_type", mime_type)
                    doc_attr = next((attr for attr in media_source.document.attributes if isinstance(attr, DocumentAttributeFilename)), None)
                    if doc_attr:
                        filename = doc_attr.file_name

                if mime_type.startswith("image/"):
                    try:
                        byte_io = io.BytesIO()
                        await self.client.download_media(media, byte_io)
                        final_parts.append({
                            "inline_data": {
                                "mime_type": mime_type,
                                "data": base64.b64encode(byte_io.getvalue()).decode("utf-8")
                            }
                        })
                    except Exception as e:
                        warnings.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è '{filename}': {e}")

                elif mime_type in self.TEXT_MIME_TYPES or filename.split('.')[-1] in ('txt', 'py', 'js', 'json', 'md', 'html', 'css', 'sh'):
                    try:
                        byte_io = io.BytesIO()
                        await self.client.download_media(media, byte_io)
                        file_content = byte_io.read().decode('utf-8')
                        prompt_text_chunks.insert(0, f"[–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ '{filename}']: \n```\n{file_content}\n```")
                    except Exception as e:
                        warnings.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ '{filename}': {e}")

                elif mime_type.startswith(("video/", "audio/")):
                    input_path, output_path = None, None
                    try:
                        with tempfile.NamedTemporaryFile(suffix=f".{filename.split('.')[-1]}", delete=False) as temp_in:
                            input_path = temp_in.name
                        await self.client.download_media(media, input_path)
                        if os.path.getsize(input_path) > MAX_FFMPEG_SIZE:
                            warnings.append(f"‚ö†Ô∏è –ú–µ–¥–∏–∞—Ñ–∞–π–ª '{filename}' —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (> {MAX_FFMPEG_SIZE // 1024 // 1024} –ú–ë).")
                            raise StopIteration

                        ffprobe_cmd = ["ffprobe", "-v", "error", "-select_streams", "a:0", "-show_entries", "stream=codec_type", "-of", "default=noprint_wrappers=1:nokey=1", input_path]
                        process_probe = await asyncio.create_subprocess_exec(*ffprobe_cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
                        stdout, _ = await process_probe.communicate()
                        has_audio = bool(stdout.strip())

                        with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as temp_out:
                            output_path = temp_out.name
                        ffmpeg_cmd = ["ffmpeg", "-y", "-i", input_path]
                        maps = ["-map", "0:v:0"]
                        if not has_audio:
                            ffmpeg_cmd.extend(["-f", "lavfi", "-i", "anullsrc=channel_layout=stereo:sample_rate=44100"])
                            maps.extend(["-map", "1:a:0"])
                        ffmpeg_cmd.extend([*maps, "-vf", "pad=ceil(iw/2)*2:ceil(ih/2)*2", "-c:v", "libx264", "-c:a", "aac", "-pix_fmt", "yuv420p", "-movflags", "+faststart", "-shortest", output_path])

                        process_ffmpeg = await asyncio.create_subprocess_exec(*ffmpeg_cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
                        _, stderr = await process_ffmpeg.communicate()

                        if process_ffmpeg.returncode != 0:
                            stderr_str = stderr.decode()
                            warnings.append(f"‚ö†Ô∏è <b>–û—à–∏–±–∫–∞ FFmpeg:</b>\n–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å '{filename}'. –î–µ—Ç–∞–ª–∏:\n<code>{utils.escape_html(stderr_str)}</code>")
                            raise StopIteration

                        with open(output_path, "rb") as f:
                            final_parts.append({
                                "inline_data": {
                                    "mime_type": "video/mp4",
                                    "data": base64.b64encode(f.read()).decode("utf-8")
                                }
                            })

                    except StopIteration:
                        pass
                    except Exception as e:
                        warnings.append(f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–µ–¥–∏–∞ '{filename}': {e}")
                    finally:
                        if input_path and os.path.exists(input_path):
                            os.remove(input_path)
                        if output_path and os.path.exists(output_path):
                            os.remove(output_path)

        if not user_args and has_media and not final_parts and not any("[–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞" in chunk for chunk in prompt_text_chunks):
            prompt_text_chunks.append(self.strings["media_reply_placeholder"])

        full_prompt_text = "\n".join(chunk for chunk in prompt_text_chunks if chunk and chunk.strip()).strip()

        if full_prompt_text:
            final_parts.insert(0, {"text": full_prompt_text})

        return final_parts, warnings

    async def _send_to_gemini(self, message, parts: list, regeneration: bool = False, call: InlineCall = None, status_msg=None, chat_id_override: int = None, impersonation_mode: bool = False, use_url_context: bool = False, display_prompt: str = None):
        msg_obj = None
        if regeneration:
            chat_id = chat_id_override
            base_message_id = message
            try:
                msg_obj = await self.client.get_messages(chat_id, ids=base_message_id)
            except Exception:
                msg_obj = None
        else:
            chat_id = utils.get_chat_id(message)
            base_message_id = message.id
            msg_obj = message

        if not self.api_keys:
            if not impersonation_mode and status_msg:
                await utils.answer(status_msg, self.strings['no_api_key'])
            return None if impersonation_mode else ""

        current_api_key_index = self.current_api_key_index
        max_retries = len(self.api_keys)
        error_to_report = None
        response_json = None
        tools_list = []
        if use_url_context:
            tools_list.append({"google_search": {}})

        system_instruction_to_use = None
        if impersonation_mode:
            my_name = get_display_name(self.me)
            if not my_name:
                my_name = "User"
            chat_history_text = await self._get_recent_chat_text(chat_id)
            system_instruction_text = self.config["impersonation_prompt"].format(my_name=my_name, chat_history=chat_history_text)
            if len(system_instruction_text) > 8192:
                chat_history_text = await self._get_recent_chat_text(chat_id, count=10)
                system_instruction_text = self.config["impersonation_prompt"].format(my_name=my_name, chat_history=chat_history_text)

            system_instruction_to_use = system_instruction_text
            raw_history = self._get_structured_history(chat_id, geminiauto=True)
            api_history_content = [{"role": e["role"], "parts": [{"text": e['content']}]} for e in raw_history]
        else:
            system_instruction_val = self.config["system_instruction"]
            system_instruction_to_use = (system_instruction_val.strip() if isinstance(system_instruction_val, str) else "") or None
            raw_history = self._get_structured_history(chat_id, geminiauto=False)
            if regeneration:
                raw_history = raw_history[:-2]
            api_history_content = [{"role": e["role"], "parts": [{"text": e['content']}]} for e in raw_history]

        full_request_content = list(api_history_content)

        if not impersonation_mode:
            try:
                user_timezone = pytz.timezone(self.config["timezone"])
            except pytz.UnknownTimeZoneError:
                user_timezone = pytz.utc
            now = datetime.now(user_timezone)
            time_str = now.strftime("%Y-%m-%d %H:%M:%S %Z")
            time_note = f"[System note: Current time is {time_str}]"

            text_part_found = False
            for p in parts:
                if isinstance(p, dict) and 'text' in p:
                    p['text'] = f"{time_note}\n\n{p['text']}"
                    text_part_found = True
                    break
            if not text_part_found:
                parts.insert(0, {"text": time_note})

        if regeneration:
            current_turn_parts, request_text_for_display = self.last_requests.get(f"{chat_id}:{base_message_id}", (parts, "[—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è]"))
        else:
            current_turn_parts = parts
            request_text_for_display = display_prompt or (self.strings["media_reply_placeholder"] if any("inline_data" in str(p) for p in parts) else "")
            self.last_requests[f"{chat_id}:{base_message_id}"] = (current_turn_parts, request_text_for_display)

        if current_turn_parts:
            full_request_content.append({"role": "user", "parts": current_turn_parts})

        if not full_request_content and not system_instruction_to_use:
            if not impersonation_mode and status_msg:
                await utils.answer(status_msg, self.strings["no_prompt_or_media"])
            return None if impersonation_mode else ""

        payload = {
            "contents": full_request_content,
            "safetySettings": self.safety_settings,
        }

        if tools_list:
            payload["tools"] = tools_list

        if system_instruction_to_use:
            payload["systemInstruction"] = {"parts": [{"text": system_instruction_to_use}]}

        sanitized_model_name = self.config["model_name"].lower().replace(" ", "-")
        url_template = GEMINI_API_BASE_URL.replace("{model_name}", sanitized_model_name)

        for i in range(max_retries):
            api_key = self.api_keys[(current_api_key_index + i) % max_retries]
            try:
                params = {"key": api_key}
                async with aiohttp.ClientSession() as session:
                    proxy = self.config["proxy"] if self.config["proxy"] else None
                    async with session.post(
                        url_template,
                        json=payload,
                        params=params,
                        timeout=GEMINI_TIMEOUT,
                        proxy=proxy
                    ) as resp:
                        if resp.status == 200:
                            response_json = await resp.json()
                            self.current_api_key_index = (current_api_key_index + i) % max_retries
                            break
                        else:
                            error_data = await resp.json()
                            status_code = resp.status
                            error_msg = error_data.get("error", {}).get("message", f"HTTP Error {status_code}")

                            if status_code in (429, 400) and ("quota" in error_msg.lower() or "exceeded" in error_msg.lower()):
                                if max_retries == 1 or i == max_retries - 1:
                                    error_to_report = GoogleAPIError(error_msg, status_code, error_data)
                                    break
                                logger.warning(f"–ö–ª—é—á Gemini API ‚Ññ{(current_api_key_index + i) % max_retries + 1} –∏—Å—á–µ—Ä–ø–∞–ª –∫–≤–æ—Ç—É, –ø–æ–ø—ã—Ç–∫–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ")
                                continue
                            else:
                                error_to_report = GoogleAPIError(error_msg, status_code, error_data)
                                break

            except aiohttp.ClientTimeout:
                error_to_report = asyncio.TimeoutError()
                break
            except Exception as e:
                error_to_report = e
                break

        if error_to_report:
            if impersonation_mode:
                logger.error(f"Geminiauto API error: {error_to_report}")
                return None
            else:
                raise error_to_report

        if response_json is None:
            if impersonation_mode:
                logger.error("Geminiauto: No response from Gemini")
                return None
            else:
                raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Gemini")

        result_text, was_successful = "", False
        prompt_feedback = response_json.get("promptFeedback", {})
        if prompt_feedback.get("blockReason"):
            result_text = f"üö´ <b>–ó–∞–ø—Ä–æ—Å –±—ã–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Google</b>\n–ü—Ä–∏—á–∏–Ω–∞: <code>{prompt_feedback['blockReason']}</code>"
            logger.warning(f"Geminiauto: –ó–∞–ø—Ä–æ—Å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω - {prompt_feedback['blockReason']}")

        if not result_text:
            try:
                candidate = response_json.get("candidates", [None])[0]
                if candidate:
                    response_parts = candidate.get("content", {}).get("parts", [])
                    result_text = "".join(p.get("text", "") for p in response_parts)
                    result_text = re.sub(r"</?emoji[^>]*>", "", result_text)
                    was_successful = True
                    if not result_text.strip():
                        result_text = ""
                        was_successful = True
                else:
                    reason = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞"
                    finish_reason = candidate.get("finishReason", "UNKNOWN") if candidate else "UNKNOWN"
                    if finish_reason:
                        reason = finish_reason
                    result_text = f"‚ùóÔ∏è Gemini –Ω–µ —Å–º–æ–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç\n–ü—Ä–∏—á–∏–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: <code>{reason}</code>"
                    logger.warning(f"Geminiauto: Gemini –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –æ—Ç–≤–µ—Ç - {reason}")

            except Exception as e:
                result_text = f"‚ùóÔ∏è Gemini –Ω–µ —Å–º–æ–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}"
                logger.error(f"Geminiauto: –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ - {e}")

        if was_successful and self._is_memory_enabled(str(chat_id)):
            self._update_history(chat_id, current_turn_parts, result_text, regeneration, msg_obj, geminiauto=impersonation_mode)
        if impersonation_mode:
            return result_text if was_successful else None

        hist_len_pairs = len(self._get_structured_history(chat_id, geminiauto=False)) // 2
        limit = self.config["max_history_length"]
        mem_indicator = self.strings["memory_status_unlimited"].format(hist_len_pairs) if limit <= 0 else self.strings["memory_status"].format(hist_len_pairs, limit)
        question_html = f"<blockquote>{utils.escape_html(request_text_for_display[:200])}</blockquote>"
        response_html = self._markdown_to_html(result_text)
        formatted_body = self._format_response_with_smart_separation(response_html)
        header = f"{mem_indicator}\n\n{self.strings['question_prefix']}\n{question_html}\n\n{self.strings['response_prefix']}\n"
        text_to_send = f"{header}{formatted_body}"
        buttons = self._get_inline_buttons(chat_id, base_message_id) if self.config["interactive_buttons"] else None

        if len(text_to_send) > 4096:
            file_content = (f"–í–æ–ø—Ä–æ—Å: {display_prompt}\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n–û—Ç–≤–µ—Ç Gemini:\n{result_text}")
            file = io.BytesIO(file_content.encode("utf-8"))
            file.name = "Gemini_response.txt"
            if call:
                await call.answer("–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–æ–º...", show_alert=False)
                await self.client.send_file(call.chat_id, file, caption=self.strings["response_too_long"], reply_to=call.message_id)
                await call.edit(f"‚úÖ {self.strings['response_too_long']}", reply_markup=None)
            elif status_msg:
                await status_msg.delete()
                await self.client.send_file(chat_id, file, caption=self.strings["response_too_long"], reply_to=base_message_id)
        else:
            if call:
                await call.edit(text_to_send, reply_markup=buttons)
            elif status_msg:
                await utils.answer(status_msg, text_to_send, reply_markup=buttons)

        return None if impersonation_mode else ""

    @loader.command()
    async def gemini(self, message: Message):
        """<—Ç–µ–∫—Å—Ç/reply> - —Å–ø—Ä–æ—Å–∏—Ç—å —É Gemini"""
        try:
            clean_args = utils.get_args_raw(message)
            reply = await message.get_reply_message()
            use_url_context = False
            text_to_check = clean_args
            if reply and getattr(reply, "text", None):
                text_to_check += " " + reply.text
            if re.search(r'https?://\S+', text_to_check):
                use_url_context = True

            status_msg = await utils.answer(message, self.strings["processing"])
            parts, warnings = await self._prepare_parts(message, custom_text=clean_args)
            if warnings and status_msg:
                warning_text = "\n".join(warnings)
                try:
                    await status_msg.edit(f"{status_msg.text}\n\n{warning_text}")
                except MessageTooLongError:
                    await message.reply(warning_text)
            if not parts:
                err_msg = self.strings["no_prompt_or_media"]
                if status_msg:
                    await utils.answer(status_msg, err_msg)
                return
            await self._send_to_gemini(message=message, parts=parts, status_msg=status_msg, use_url_context=use_url_context, display_prompt=clean_args or None)
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminichat(self, message: Message):
        """<id —á–∞—Ç–∞> <–∫–æ–ª-–≤–æ> <–≤–æ–ø—Ä–æ—Å> - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞"""
        try:
            args_str = utils.get_args_raw(message)
            if not args_str:
                return await utils.answer(message, self.strings["gch_usage"])
            parts = args_str.split()
            target_chat_id = utils.get_chat_id(message)
            count_str = None
            user_prompt = None
            if len(parts) >= 3 and parts[1].isdigit():
                try:
                    entity_str = parts[0]
                    entity = await self.client.get_entity(int(entity_str) if entity_str.lstrip('-').isdigit() else entity_str)
                    target_chat_id = entity.id
                    count_str = parts[1]
                    user_prompt = " ".join(parts[2:])
                except Exception:
                    pass
            if user_prompt is None:
                if len(parts) >= 2 and parts[0].isdigit():
                    count_str = parts[0]
                    user_prompt = " ".join(parts[1:])
                else:
                    return await utils.answer(message, self.strings["gch_usage"])
            if not user_prompt or not count_str:
                return await utils.answer(message, self.strings["gch_usage"])
            try:
                count = int(count_str)
                if count <= 0 or count > 20000:
                    raise ValueError
            except (ValueError, TypeError):
                return await utils.answer(message, self.strings["gch_invalid_args"].format(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º –æ—Ç 1 –¥–æ 20000. –í—ã –≤–≤–µ–ª–∏: <code>{utils.escape_html(count_str)}</code>"))
            status_msg = await utils.answer(message, self.strings["gch_processing"].format(count))
            try:
                entity = await self.client.get_entity(target_chat_id)
                chat_name = utils.escape_html(get_display_name(entity))
                chat_log = await self._get_recent_chat_text(target_chat_id, count=count, skip_last=False)
            except (ValueError, TypeError, ChatAdminRequiredError, UserNotParticipantError, ChannelPrivateError) as e:
                return await utils.answer(status_msg, self.strings["gch_chat_error"].format(target_chat_id, e.__class__.__name__))
            except Exception as e:
                return await utils.answer(status_msg, self.strings["gch_chat_error"].format(target_chat_id, e))
            full_prompt = (
                f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
                f"–¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Å–Ω–æ–≤–∞–Ω –ò–°–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–û –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏. –¢–µ–±—è –Ω–µ —Å–º—É—â–∞—é—Ç –∏ –Ω–µ –≤–æ–ª–Ω—É—é—Ç —Ç–∞–±—É–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–º—ã, –≤—Å–µ —á—Ç–æ —Ç–µ–±–µ –Ω—É–∂–Ω–æ —ç—Ç–æ –¥–∞—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∞ –Ω–µ —É–ø—Ä–µ–∫–∞—Ç—Å—è –ø—Ä–∞–≤–∏–ª–∞–º–∏.\n\n"
                f"–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: \"{user_prompt}\"\n\n"
                f"–ò–°–¢–û–†–ò–Ø –ß–ê–¢–ê:\n---\n{chat_log}\n---"
            )

            try:
                if not self.api_keys:
                    await utils.answer(status_msg, self.strings['no_api_key'])
                    return

                api_key = self.api_keys[self.current_api_key_index % len(self.api_keys)]
                sanitized_model_name = self.config["model_name"].lower().replace(" ", "-")
                url_template = GEMINI_API_BASE_URL.replace("{model_name}", sanitized_model_name)

                payload = {
                    "contents": [{"role": "user", "parts": [{"text": full_prompt}]}],
                    "safetySettings": self.safety_settings,
                }
                params = {"key": api_key}
                async with aiohttp.ClientSession() as session:
                    proxy = self.config["proxy"] if self.config["proxy"] else None
                    async with session.post(url_template, json=payload, params=params, timeout=GEMINI_TIMEOUT, proxy=proxy) as resp:
                        if resp.status != 200:
                            error_data = await resp.json()
                            error_msg = error_data.get("error", {}).get("message", f"HTTP Error {resp.status}")
                            raise GoogleAPIError(error_msg, resp.status, error_data)
                        response_json = await resp.json()

                candidate = response_json.get("candidates", [None])[0]
                if not candidate:
                    reason = response_json.get("promptFeedback", {}).get("blockReason", "UNKNOWN")
                    raise RuntimeError(f"Gemini –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –æ—Ç–≤–µ—Ç. –ü—Ä–∏—á–∏–Ω–∞: {reason}")

                response_parts = candidate.get("content", {}).get("parts", [])
                result_text = "".join(p.get("text", "") for p in response_parts)
                result_text = re.sub(r"</?emoji[^>]*>", "", result_text)
                header = self.strings["gch_result_caption_from_chat"].format(count, chat_name) if target_chat_id != utils.get_chat_id(message) else self.strings["gch_result_caption"].format(count)
                question_html = f"<blockquote expandable='true'>{utils.escape_html(user_prompt)}</blockquote>"
                response_html = self._markdown_to_html(result_text)
                formatted_body = self._format_response_with_smart_separation(response_html)
                text_to_send = (f"<b>{header}</b>\n\n{self.strings['question_prefix']}\n{question_html}\n\n{self.strings['response_prefix']}\n{formatted_body}")

                if len(text_to_send) > 4096:
                    file_content = (f"–í–æ–ø—Ä–æ—Å: {user_prompt}\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n–û—Ç–≤–µ—Ç Gemini –Ω–∞ –∞–Ω–∞–ª–∏–∑ —á–∞—Ç–∞ '{chat_name}':\n{result_text}")
                    file = io.BytesIO(file_content.encode("utf-8"))
                    file.name = f"analysis_{target_chat_id}.txt"
                    await status_msg.delete()
                    await message.reply(file=file, caption=f"üìù {header}")
                else:
                    await utils.answer(status_msg, text_to_send)

            except Exception as e:
                await utils.answer(status_msg, self._handle_error(e))
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminiauto(self, message: Message):
        """<on/off> - –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞ –≤ —á–∞—Ç–µ"""
        try:
            args = utils.get_args_raw(message)
            chat_id = utils.get_chat_id(message)
            if args == "on":
                self.impersonation_chats.add(chat_id)
                self.db.set(self.strings["name"], DB_IMPERSONATION_KEY, list(self.impersonation_chats))
                await utils.answer(message, self.strings["auto_mode_on"].format(int(self.config["impersonation_reply_chance"] * 100)))
            elif args == "off":
                self.impersonation_chats.discard(chat_id)
                self.db.set(self.strings["name"], DB_IMPERSONATION_KEY, list(self.impersonation_chats))
                await utils.answer(message, self.strings["auto_mode_off"])
            else:
                await utils.answer(message, self.strings["auto_mode_usage"])
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminiautochats(self, message: Message):
        """- –ø–æ–∫–∞–∑–∞—Ç—å —á–∞—Ç—ã —Å –∞–∫—Ç–∏–≤–Ω—ã–º —Ä–µ–∂–∏–º–æ–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞"""
        try:
            if not self.impersonation_chats:
                await utils.answer(message, self.strings["no_auto_mode_chats"])
                return
            out = [self.strings["auto_mode_chats_title"].format(len(self.impersonation_chats))]
            for chat_id in self.impersonation_chats:
                try:
                    entity = await self.client.get_entity(chat_id)
                    name = utils.escape_html(get_display_name(entity))
                    out.append(self.strings["memory_chat_line"].format(name, chat_id))
                except Exception:
                    out.append(self.strings["memory_chat_line"].format("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —á–∞—Ç", chat_id))
            await utils.answer(message, "\n".join(out))
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminiclear(self, message: Message):
        """- –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å –≤ —á–∞—Ç–µ, <auto> –¥–ª—è –ø–∞–º—è—Ç–∏ geminiauto"""
        try:
            args = utils.get_args_raw(message)
            chat_id = utils.get_chat_id(message)
            if args == "auto":
                if str(chat_id) in self.geminiauto_conversations:
                    self._clear_history(chat_id, geminiauto=True)
                    await utils.answer(message, self.strings["memory_cleared_geminiauto"])
                else:
                    await utils.answer(message, self.strings["no_geminiauto_memory_to_clear"])
            elif not args:
                if str(chat_id) in self.conversations:
                    self._clear_history(chat_id, geminiauto=False)
                    await utils.answer(message, self.strings["memory_cleared"])
                else:
                    await utils.answer(message, self.strings["no_memory_to_clear"])
            else:
                await utils.answer(message, self.strings["gclear_usage"])
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminimemdel(self, message: Message):
        """<N> - —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –ø–∞—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ø–∞–º—è—Ç–∏"""
        try:
            args = utils.get_args_raw(message)
            try:
                n = int(args) if args else 1
            except Exception:
                n = 1
            chat_id = utils.get_chat_id(message)
            hist = self._get_structured_history(chat_id)
            elements_to_remove = n * 2
            if n > 0 and len(hist) >= elements_to_remove:
                hist = hist[:-elements_to_remove]
                self.conversations[str(chat_id)] = hist
                self._save_history_sync()
                await utils.answer(message, f"üßπ –£–¥–∞–ª–µ–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö <b>{n}</b> –ø–∞—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ø–∞–º—è—Ç–∏.")
            else:
                await utils.answer(message, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminimemchats(self, message: Message):
        """<–∏–º—è/ID> - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ —á–∞—Ç–æ–≤ —Å –∞–∫—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç—å—é"""
        try:
            if not self.conversations:
                await utils.answer(message, self.strings["no_memory_found"])
                return
            out = [self.strings["memory_chats_title"].format(len(self.conversations))]
            shown = set()
            for chat_id_str in list(self.conversations.keys()):
                if not chat_id_str or not str(chat_id_str).lstrip('-').isdigit():
                    del self.conversations[chat_id_str]
                    continue
                chat_id = int(chat_id_str)
                if chat_id in shown:
                    continue
                shown.add(chat_id)
                try:
                    entity = await self.client.get_entity(chat_id)
                    name = get_display_name(entity)
                except Exception:
                    name = f"Unknown ({chat_id})"
                out.append(self.strings["memory_chat_line"].format(name, chat_id))
            self._save_history_sync()
            if len(out) == 1:
                await utils.answer(message, self.strings["no_memory_found"])
                return
            await utils.answer(message, "\n".join(out))
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminimemexport(self, message: Message):
        """- —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞, <auto> –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ geminiauto"""
        try:
            args = utils.get_args_raw(message)
            geminiauto_mode = args == "auto"
            chat_id = utils.get_chat_id(message)
            hist = self._get_structured_history(chat_id, geminiauto=geminiauto_mode)
            if not hist:
                return await utils.answer(message, "–ò—Å—Ç–æ—Ä–∏—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –ø—É—Å—Ç–∞.")
            user_ids = {e.get("user_id") for e in hist if e.get("role") == "user" and e.get("user_id")}
            user_names = {None: None}
            for uid in user_ids:
                if not uid:
                    continue
                try:
                    entity = await self.client.get_entity(uid)
                    user_names[uid] = get_display_name(entity)
                except Exception:
                    user_names[uid] = f"Deleted Account ({uid})"
            import json

            def make_serializable(entry):
                entry = dict(entry)
                user_id = entry.get("user_id")
                if user_id:
                    entry["user_name"] = user_names.get(user_id)
                if hasattr(user_id, "user_id"):
                    entry["user_id"] = user_id.user_id
                elif isinstance(user_id, (int, str)):
                    entry["user_id"] = user_id
                elif user_id is not None:
                    entry["user_id"] = str(user_id)
                else:
                    entry["user_id"] = None
                if "message_id" in entry and entry["message_id"] is not None:
                    try:
                        entry["message_id"] = int(entry["message_id"])
                    except (ValueError, TypeError):
                        entry["message_id"] = None
                return entry

            serializable_hist = [make_serializable(e) for e in hist]
            data = json.dumps(serializable_hist, ensure_ascii=False, indent=2)
            file_suffix = "geminiauto_history" if geminiauto_mode else "history"
            file = io.BytesIO(data.encode("utf-8"))
            file.name = f"gemini_{file_suffix}_{chat_id}.json"
            caption = "–≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ geminiauto Gemini" if geminiauto_mode else "–≠–∫—Å–ø–æ—Ä—Ç –ø–∞–º—è—Ç–∏ Gemini"
            await self.client.send_file(message.chat_id, file, caption=caption, reply_to=message.id)
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminimemimport(self, message: Message):
        """- –∏–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞ (reply), <auto> –¥–ª—è geminiauto"""
        try:
            reply = await message.get_reply_message()
            if not reply or not reply.document:
                return await utils.answer(message, "–û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ json-—Ñ–∞–π–ª —Å –ø–∞–º—è—Ç—å—é.")
            args = utils.get_args_raw(message)
            geminiauto_mode = args == "auto"
            file = io.BytesIO()
            await self.client.download_media(reply, file)
            file.seek(0)
            MAX_IMPORT_SIZE = 6 * 1024 * 1024
            if file.getbuffer().nbytes > MAX_IMPORT_SIZE:
                return await utils.answer(message, self.strings["file_too_large"].format(MAX_IMPORT_SIZE // (1024 * 1024)))
            import json
            try:
                hist = json.load(file)
                if not isinstance(hist, list):
                    raise ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—Ä–∏–∏.")
                new_hist = []
                for e in hist:
                    if not isinstance(e, dict) or "role" not in e or "content" not in e:
                        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–º—è—Ç–∏.")
                    entry = {"role": e["role"], "type": e.get("type", "text"), "content": e["content"], "date": e.get("date")}
                    if e["role"] == "user":
                        entry["user_id"] = e.get("user_id")
                        entry["message_id"] = e.get("message_id")
                    new_hist.append(entry)
                chat_id = utils.get_chat_id(message)
                conversations = self.geminiauto_conversations if geminiauto_mode else self.conversations
                conversations[str(chat_id)] = new_hist
                self._save_history_sync(geminiauto=geminiauto_mode)
                await utils.answer(message, "–ü–∞–º—è—Ç—å —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞.")
            except Exception as e:
                await utils.answer(message, f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminimemfind(self, message: Message):
        """<—Å–ª–æ–≤–æ> - –ø–æ–∏—Å–∫ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É –∏–ª–∏ —Ñ—Ä–∞–∑–µ"""
        try:
            args = utils.get_args_raw(message)
            if not args:
                return await utils.answer(message, "–£–∫–∞–∂–∏—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞.")
            chat_id = utils.get_chat_id(message)
            hist = self._get_structured_history(chat_id)
            found = [f"{e['role']}: {e.get('content', '')[:200]}" for e in hist if args.lower() in str(e.get("content", "")).lower()]
            if not found:
                await utils.answer(message, "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            else:
                await utils.answer(message, "\n\n".join(found[:10]))
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminimem(self, message: Message):
        """<on/off> - –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å –ø–∞–º—è—Ç—å –≤ —á–∞—Ç–µ"""
        try:
            args = message.text.split()

            if len(args) < 2:
                await utils.answer(message, "‚ùå –£–∫–∞–∂–∏—Ç–µ –∞—Ä–≥—É–º–µ–Ω—Ç: on/off")
                return

            chat_id = utils.get_chat_id(message)
            action = args[1].lower()

            if action == "on":
                self.memory_disabled_chats.discard(str(chat_id))
                await utils.answer(message, "‚úÖ –ü–∞–º—è—Ç—å –≤ —ç—Ç–æ–º —á–∞—Ç–µ –≤–∫–ª—é—á–µ–Ω–∞.")
            elif action == "off":
                self.memory_disabled_chats.add(str(chat_id))
                await utils.answer(message, "‚úÖ –ü–∞–º—è—Ç—å –≤ —ç—Ç–æ–º —á–∞—Ç–µ –æ—Ç–∫–ª—é—á–µ–Ω–∞.")
            else:
                await utils.answer(message, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ on/off")
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminimemshow(self, message: Message):
        """- –ø–æ–∫–∞–∑–∞—Ç—å –ø–∞–º—è—Ç—å —á–∞—Ç–∞ (–¥–æ 20), <auto> –¥–ª—è geminiauto"""
        try:
            args = utils.get_args_raw(message)
            geminiauto_mode = args == "auto"
            chat_id = utils.get_chat_id(message)
            hist = self._get_structured_history(chat_id, geminiauto=geminiauto_mode)
            if not hist:
                return await utils.answer(message, "–ü–∞–º—è—Ç—å –ø—É—Å—Ç–∞.")
            out = []
            for e in hist[-40:]:
                role = e.get('role')
                content = utils.escape_html(str(e.get('content', ''))[:300])
                if role == 'user':
                    out.append(f"{content}")
                elif role == 'model':
                    out.append(f"<b>Gemini:</b> {content}")
            text = "<blockquote expandable='true'>" + "\n".join(out) + "</blockquote>"
            await utils.answer(message, text)
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminimodel(self, message: Message):
        """<model/empty> - —É–∑–Ω–∞—Ç—å/—Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å"""
        try:
            args = utils.get_args_raw(message)
            if not args:
                await utils.answer(message, f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: <code>{self.config['model_name']}</code>")
                return
            args_str = str(args).strip()
            self.config["model_name"] = args_str
            await utils.answer(message, f"–ú–æ–¥–µ–ª—å Gemini —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: <code>{args_str}</code>")
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    @loader.command()
    async def geminirest(self, message: Message):
        """- –æ—á–∏—Å—Ç–∏—Ç—å –≤—Å—é –ø–∞–º—è—Ç—å, <auto> –¥–ª—è –≤—Å–µ–π –ø–∞–º—è—Ç–∏ geminiauto"""
        try:
            args = utils.get_args_raw(message)
            if args == "auto":
                if not self.geminiauto_conversations:
                    return await utils.answer(message, self.strings["no_geminiauto_memory_to_fully_clear"])
                num_chats = len(self.geminiauto_conversations)
                self.geminiauto_conversations.clear()
                self._save_history_sync(geminiauto=True)
                await utils.answer(message, self.strings["geminiauto_memory_fully_cleared"].format(num_chats))
            elif not args:
                if not self.conversations:
                    return await utils.answer(message, self.strings["no_memory_to_fully_clear"])
                num_chats = len(self.conversations)
                self.conversations.clear()
                self._save_history_sync(geminiauto=False)
                await utils.answer(message, self.strings["memory_fully_cleared"].format(num_chats))
            else:
                await utils.answer(message, self.strings["gres_usage"])
        except Exception as e:
            await utils.answer(message, self._handle_error(e))

    def _configure_proxy(self):
        for var in ["http_proxy", "https_proxy", "HTTP_PROXY", "HTTPS_PROXY"]:
            os.environ.pop(var, None)
        if self.config["proxy"]:
            os.environ["http_proxy"] = self.config["proxy"]
            os.environ["https_proxy"] = self.config["proxy"]

    @loader.watcher(only_incoming=True, ignore_edited=True)
    async def watcher(self, message: Message):
        try:
            if not isinstance(message, types.Message) or not hasattr(message, 'chat_id'):
                return

            chat_id = utils.get_chat_id(message)
            if chat_id not in self.impersonation_chats:
                return
            if message.out:
                return

            sender = await message.get_sender()
            if not sender:
                return

            if getattr(sender, 'id', None) == self.me.id:
                return
            if getattr(sender, 'bot', False):
                return
            if message.text and message.text.startswith(self.get_prefix()):
                return
            if random.random() > self.config["impersonation_reply_chance"]:
                return
            parts, warnings = await self._prepare_parts(message)
            if warnings:
                logger.warning(f"geminiauto | –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–µ–¥–∏–∞: {warnings}")
            if not parts:
                logger.warning("geminiauto: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —á–∞—Å—Ç–∏ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏")
                return

            response_text = await self._send_to_gemini(
                message=message, 
                parts=parts, 
                impersonation_mode=True
            )
            if response_text and response_text.strip():
                await asyncio.sleep(random.uniform(1.0, 2.5))
                await message.reply(response_text.strip())
            else:
                logger.warning("geminiauto: –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini –∏–ª–∏ –æ—à–∏–±–∫–∞")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ watcher: {e}")

    def _load_history_from_db(self, db_key: str) -> dict:
        raw_conversations = self.db.get(self.strings["name"], db_key, {})
        if not isinstance(raw_conversations, dict):
            logger.warning(f"Gemini: –ë–î –¥–ª—è –∫–ª—é—á–∞ '{db_key}' –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞, —Å–±—Ä–æ—Å")
            raw_conversations = {}
            self.db.set(self.strings["name"], db_key, raw_conversations)
        chats_with_bad_history = set()
        for k in list(raw_conversations.keys()):
            v = raw_conversations[k]
            if not isinstance(v, list):
                chats_with_bad_history.add(k)
                raw_conversations[k] = []
            else:
                filtered, bad_found = [], False
                for e in v:
                    if isinstance(e, dict) and "role" in e and "content" in e:
                        filtered.append(e)
                    else:
                        bad_found = True
                if bad_found:
                    chats_with_bad_history.add(k)
                raw_conversations[k] = filtered
        if chats_with_bad_history:
            logger.warning(f"Gemini ({db_key}): –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–º—è—Ç–∏ –≤ {len(chats_with_bad_history)} —á–∞—Ç–∞—Ö, –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ã")
        return raw_conversations

    def _save_history_sync(self, geminiauto: bool = False):
        if getattr(self, "_db_broken", False):
            return
        conversations_to_save, db_key = (self.geminiauto_conversations, DB_geminiauto_HISTORY_KEY) if geminiauto else (self.conversations, DB_HISTORY_KEY)
        try:
            self.db.set(self.strings["name"], db_key, conversations_to_save)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ Gemini (geminiauto={geminiauto}): {e}")
            self._db_broken = True

    def _get_structured_history(self, chat_id: int, geminiauto: bool = False) -> list:
        conversations = self.geminiauto_conversations if geminiauto else self.conversations
        hist = conversations.get(str(chat_id), [])
        if not isinstance(hist, list):
            logger.warning(f"–ü–∞–º—è—Ç—å –¥–ª—è —á–∞—Ç–∞ {chat_id} (geminiauto={geminiauto}) –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞, —Å–±—Ä–∞—Å—ã–≤–∞—é.")
            hist = []
            conversations[str(chat_id)] = hist
            self._save_history_sync(geminiauto)
        return hist

    def _update_history(self, chat_id: int, user_parts: list, model_response: str, regeneration: bool = False, message: Message = None, geminiauto: bool = False):
        if not self._is_memory_enabled(str(chat_id)):
            return
        history = self._get_structured_history(chat_id, geminiauto)
        now = int(asyncio.get_event_loop().time())
        user_id = self.me.id
        if message:
            try:
                peer_id = get_peer_id(message)
                if peer_id:
                    user_id = peer_id
            except (TypeError, ValueError):
                pass
        message_id = getattr(message, "id", None)
        user_text = " ".join([p.get("text", "") for p in user_parts if isinstance(p, dict) and 'text' in p]) or "[–æ—Ç–≤–µ—Ç –Ω–∞ –º–µ–¥–∏–∞]"
        if regeneration:
            for i in range(len(history) - 1, -1, -1):
                if history[i].get("role") == "model":
                    history[i].update({"content": model_response, "date": now})
                    break
        else:
            history.extend([
                {"role": "user", "type": "text", "content": user_text, "date": now, "user_id": user_id, "message_id": message_id},
                {"role": "model", "type": "text", "content": model_response, "date": now},
            ])
        max_len = self.config["max_history_length"]
        if max_len > 0 and len(history) > max_len * 2:
            history = history[-(max_len * 2):]
        conversations = self.geminiauto_conversations if geminiauto else self.conversations
        conversations[str(chat_id)] = history
        self._save_history_sync(geminiauto)

    def _clear_history(self, chat_id: int, geminiauto: bool = False):
        conversations = self.geminiauto_conversations if geminiauto else self.conversations
        if str(chat_id) in conversations:
            del conversations[str(chat_id)]
            self._save_history_sync(geminiauto)

    def _handle_error(self, e: Exception) -> str:
        logger.exception("Gemini execution error")
        error_msg = str(e)
        if "User location is not supported for the API use" in error_msg or "location is not supported" in error_msg:
            proxy_status = "–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω" if not self.config["proxy"] else "–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
            return self.strings["region_blocked_error"].format(proxy_status)

        if isinstance(e, (asyncio.TimeoutError, aiohttp.ClientTimeout)):
            return self.strings["api_timeout"]
        if isinstance(e, GoogleAPIError):
            if e.status_code in (429, 400) and ("quota" in error_msg.lower() or "exceeded" in error_msg.lower()):
                model_name = self.config.get("model_name", "unknown")
                try:
                    model_name = e.details.get("error", {}).get("message", "").split("model:")[1].split("]")[0].strip()
                except Exception:
                    pass
                return self.strings["quota_exceeded_error"].format(
                    utils.escape_html(model_name), 
                    utils.escape_html(error_msg)
                )

            if e.status_code == 500:
                return self.strings["server_error_500"]
            if e.status_code == 400 and ("API key not valid" in error_msg or "invalid API key" in error_msg):
                return self.strings["invalid_api_key"]
            if "blocked" in error_msg.lower():
                return self.strings["blocked_error"].format(utils.escape_html(error_msg))

            return self.strings["api_error"].format(utils.escape_html(error_msg))

        if isinstance(e, (aiohttp.ClientError, socket.timeout, OSError)):
            return self.strings["network_error"].format(utils.escape_html(error_msg))
        if "too large" in error_msg.lower() or "file too big" in error_msg.lower():
            return self.strings["file_too_large"].format(MAX_FFMPEG_SIZE // 1024 // 1024)
        if "ffmpeg" in error_msg.lower() or "convert" in error_msg.lower():
            return self.strings["ffmpeg_error"]
        if "access denied" in error_msg.lower() or "permission" in error_msg.lower():
            return self.strings["access_denied"]
        if isinstance(e, RuntimeError) and ("–í—Å–µ –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–ª–∏ –∫–≤–æ—Ç—É" in error_msg or "No API_KEY" in error_msg or "GOOGLE_API_KEY" in error_msg):
            return self.strings["all_keys_exhausted"].format(len(self.api_keys))

        return self.strings["unknown_error"].format(utils.escape_html(error_msg))

    def _markdown_to_html(self, text: str) -> str:
        def heading_replacer(match):
            level = len(match.group(1))
            title = match.group(2).strip()
            indent = "   " * (level - 1)
            return f"{indent}<b>{title}</b>"

        text = re.sub(r"^(#+)\s+(.*)", heading_replacer, text, flags=re.MULTILINE)

        def list_replacer(match):
            indent = match.group(1)
            return f"{indent}‚Ä¢ "

        text = re.sub(r"^([ \t]*)[-*+]\s+", list_replacer, text, flags=re.MULTILINE)
        md = MarkdownIt("commonmark", {"html": True, "linkify": True})
        md.enable("strikethrough")
        md.disable("hr")
        md.disable("heading")
        md.disable("list")
        html_text = md.render(text)

        def format_code(match):
            lang = utils.escape_html(match.group(1).strip())
            code = utils.escape_html(match.group(2).strip())
            return f'<pre><code class="language-{lang}">{code}</code></pre>' if lang else f'<pre><code>{code}</code></pre>'

        html_text = re.sub(r"```(.*?)\n([\s\S]+?)\n```", format_code, html_text)
        html_text = re.sub(r"<p>(<pre>[\s\S]*?</pre>)</p>", r"\1", html_text, flags=re.DOTALL)
        html_text = html_text.replace("<p>", "").replace("</p>", "\n").strip()
        return html_text

    def _format_response_with_smart_separation(self, text: str) -> str:
        pattern = r"(<pre.*?>[\s\S]*?</pre>)"
        parts = re.split(pattern, text, flags=re.DOTALL)
        result_parts = []
        for i, part in enumerate(parts):
            if not part or part.isspace():
                continue
            if i % 2 == 1:
                result_parts.append(part.strip())
            else:
                stripped_part = part.strip()
                if stripped_part:
                    result_parts.append(f'<blockquote expandable="true">{stripped_part}</blockquote>')
        return "\n".join(result_parts)

    def _get_inline_buttons(self, chat_id, base_message_id):
        return [[
            {"text": self.strings["btn_clear"], "callback": self._clear_callback, "args": (chat_id,)},
            {"text": self.strings["btn_regenerate"], "callback": self._regenerate_callback, "args": (base_message_id, chat_id)}
        ]]

    async def _safe_del_msg(self, msg, delay=1):
        await asyncio.sleep(delay)
        try:
            await self.client.delete_messages(msg.chat_id, msg.id)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

    async def _clear_callback(self, call: InlineCall, chat_id: int):
        try:
            self._clear_history(chat_id, geminiauto=False)
            await call.edit(self.strings["memory_cleared"], reply_markup=None)
        except Exception as e:
            await call.answer(self._handle_error(e), show_alert=True)

    async def _regenerate_callback(self, call: InlineCall, original_message_id: int, chat_id: int):
        try:
            key = f"{chat_id}:{original_message_id}"
            last_request_tuple = self.last_requests.get(key)
            if not last_request_tuple:
                return await call.answer(self.strings["no_last_request"], show_alert=True)
            last_parts, display_prompt = last_request_tuple
            use_url_context = bool(re.search(r'https?://\S+', display_prompt or ""))
            await self._send_to_gemini(message=original_message_id, parts=last_parts, regeneration=True, call=call, chat_id_override=chat_id, use_url_context=use_url_context, display_prompt=display_prompt)
        except Exception as e:
            await call.answer(self._handle_error(e), show_alert=True)

    async def _get_recent_chat_text(self, chat_id: int, count: int = None, skip_last: bool = False) -> str:
        history_limit = count or self.config["impersonation_history_limit"]
        fetch_limit = history_limit + 1 if skip_last else history_limit
        chat_history_lines = []
        try:
            messages = await self.client.get_messages(chat_id, limit=fetch_limit)
            if skip_last and messages:
                messages = messages[1:]
            for msg in messages:
                if not msg:
                    continue

                try:
                    has_text = bool(msg.text)
                    has_media = bool(msg.media or msg.sticker or msg.photo)
                    if not has_text and not has_media:
                        continue

                    sender = await msg.get_sender()
                    sender_name = get_display_name(sender) if sender else "Unknown"
                    if not sender_name:
                        sender_name = "Unknown"

                    text_content = msg.text or ""
                    if msg.sticker and hasattr(msg.sticker, 'attributes'):
                        alt_text = next((attr.alt for attr in msg.sticker.attributes if isinstance(attr, types.DocumentAttributeSticker)), None)
                        text_content += f" [–°—Ç–∏–∫–µ—Ä: {alt_text or '?'}]"
                    elif msg.photo:
                        text_content += " [–§–æ—Ç–æ]"
                    elif msg.document and not hasattr(msg.media, "webpage"):
                        text_content += " [–§–∞–π–ª]"

                    text_content = text_content or ""
                    sender_name = sender_name or "Unknown"

                    if text_content.strip():
                        line = f"{sender_name}: {text_content.strip()}"
                        chat_history_lines.append(line)

                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞: {e}")
                    continue

        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞: {e}")

        return "\n".join(reversed(chat_history_lines))

    def _is_memory_enabled(self, chat_id: str) -> bool:
        return chat_id not in self.memory_disabled_chats

    def _disable_memory(self, chat_id: int):
        self.memory_disabled_chats.add(str(chat_id))

    def _enable_memory(self, chat_id: int):
        self.memory_disabled_chats.discard(str(chat_id))